{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "59c28a14",
      "metadata": {
        "id": "59c28a14"
      },
      "source": [
        "# Báo cáo đồ án môn \"Khoa học dữ liệu ứng dụng\"\n",
        "\n",
        "Nhóm 9:\n",
        "1. 18120533 - Dương Đoàn Bảo Sơn - https://github.com/baosonhcmus\n",
        "2. 18120498 - Nguyễn Thị Hồng Nhung - https://github.com/nhung-ng\n",
        "3. 18120009 - Vương Gia Bảo - https://github.com/bao12012000\n",
        "4. 18120543 - Trần Đại Tài - https://github.com/trandaitai327\n",
        "\n",
        "Link thùng chứa Github của nhóm: [Link](https://github.com/trandaitai327/IEEE-CIS-Fraud-Detection)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7494dd75",
      "metadata": {
        "id": "7494dd75"
      },
      "source": [
        "## Mô tả bài toán"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54c48b7",
      "metadata": {
        "id": "b54c48b7"
      },
      "source": [
        "[IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection/overview)\n",
        "### Bối cảnh:\n",
        "Đây là cuộc thì được tổ chức bởi  Các nhà nghiên cứu từ IEEE Computational Intelligence Society (IEEE-CIS) hợp tác với công ty dịch vụ thanh toán hàng đầu thế giới - Vesta Corporation  nhằm tìm kiếm các giải pháp tốt nhất cho việc phát hiện gian lận từ các giao dịch của khách hàng, giúp hàng trăm nghìn doanh nghiệp giảm thất thoát do gian lận và tăng doanh thu của họ.\n",
        "### Đánh giá:\n",
        "Độ đo [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)(AUC)\n",
        "### Submission File:\n",
        "Đối với mỗi `TransactionID` trong tập thử nghiệm, bạn phải dự đoán một xác suất cho biến `isFraud`. Tệp phải chứa tiêu đề và có định dạng sau:\n",
        "\n",
        "TransactionID,isFraud\n",
        "\n",
        "3663549,0.5\n",
        "\n",
        "3663550,0.5\n",
        "\n",
        "3663551,0.5\n",
        "\n",
        "etc.\n",
        "\n",
        "### Dữ liệu:\n",
        "- Dữ liệu đến từ các giao dịch thương mại điện tử của các khách hàng của Vesta bao gồm các features từ loại thiết bị cho đến features của sản phẩm cũng như thông tin về các giao dịch và cho phép tạo các features mới để cải thiện kết quả của model.\n",
        "\n",
        "- Dữ liệu được chia thành hai file:  identity và transactionđược nối với nhau bằng TransactionID. Không phải tất cả các giao dịch đều có thông tin nhận dạng tương ứng.\n",
        "\n",
        "- Các thuộc tính:\n",
        "  + Transaction Table:\n",
        "    * TransactionDT: thời gian tính từ một móc tham chiếu  (ngày/ giờ) nhất định (không phải thời gian thực tế)\n",
        "    * TransactionAMT: số tiền thanh toán cho giao dịch  (USD)\n",
        "    * ProductCD:  mã sản phẩm  của mỗi giao dịch\n",
        "    * card1 - card6: thông tin thẻ thanh toán, chẳng hạn như loại thẻ, ngân hàng phát hành,,quốc gia, v.v.\n",
        "    * addr: địa chỉ user\n",
        "    * dist: khoảng cách giữa (không giới hạn) địa chỉ thanh toán, địa chỉ gửi , mã zip, địa chỉ IP, mã vùng điện thoại, v.v.”\n",
        "    * P_ and (R__) emaildomain: tên miền email của người mua và người nhận, một số giao dịch nhất định không cần người nhận, do đó, có thể null\n",
        "    * C1-C14: counting  ,có bao nhiêu địa chỉ được tìm thấy có liên quan đến thẻ thanh toán, v.v. (Ý nghĩa thực tế được che giấu)\n",
        "“Bạn có thể vui lòng cho thêm ví dụ về số đếm trong các biến C1-15 không? số điện thoại, địa chỉ email, tên liên quan đến người dùng?\n",
        "    * D1-D15: timedelta (chẳng hạn thời gian giữa các lần giao dịch)\n",
        "    * M1-M9: match ( tên trên thẻ , địa chỉ,vv..vv.)\n",
        "    * Vxxx: các features  bao gồm xếp hạng, đếm và các quan hệ thực thể khác.\n",
        "\n",
        "    “Ví dụ: số lần thẻ thanh toán được liên kết với IP và email hoặc địa chỉ xuất hiện trong phạm vi thời gian 24 giờ, v.v.” \n",
        "    * Categorical Features: ProductCD, card1 - card6, addr1, addr2, P_emaildomain, R_emaildomain, M1 - M9\n",
        "\n",
        "  + Indentity Table:\n",
        "    * Các biến trong bảng này là thông tin giúp xác thực/nhận dạng - thông tin kết nối mạng (IP, ISP, Proxy, v.v.) và chữ ký số (UA / browser / os / version, v.v.) được liên kết với các giao dịch.Chúng được thu thập bởi hệ thống chống gian lận của Vesta và các đối tác bảo mật kỹ thuật số.\n",
        "(Các tên trường được che dấu và từ điển ghép nối sẽ không được cung cấp để bảo vệ quyền riêng tư và thỏa thuận hợp đồng) \n",
        "    * Categorical Features: DeviceType, DeviceInfo\n",
        "    * id_12 - id_38 : là các numerical features cho Identity như rank thiết bị/ip_domain/ proxy, v.v. Ngoài ra, nó còn ghi lại dấu vân tay hành vi như số lần đăng nhập tài khoản / không đăng nhập được, thời gian đăng nhập tài khoản vẫn còn trên trang,.v..v"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4797906c",
      "metadata": {
        "id": "4797906c"
      },
      "source": [
        "## Giải quyết bài toán"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd44dab",
      "metadata": {
        "id": "ffd44dab"
      },
      "source": [
        "[Giải pháp hạng 1 - Chris Deotte & Konstantin Yakovlev](https://www.kaggle.com/c/ieee-fraud-detection/discussion/111284?fbclid=IwAR1CdMPVYUNmvIgxfDQbExwpYZZyU8SiMICVvfXwJEOSRIFEjE-2lUapRMg)   \n",
        "**Time is not most important !!!**\n",
        "- Không phải bản chất của gian lận thay đổi theo thời gian mà là do tập khách hàng thay đổi theo thời gian.\n",
        "- Thử thách của cuộc thi này là dự đoán những khách hàng mà chúng ta không nhìn thấy được. Thực vậy dữ liệu private gồm 68.2% khách hàng chúng ta không nhìn thấy trong tập train, 16.4% tồn tại trong tập train và tập test, 15,4% là không chắc chắn (số liệu sau khi cuộc thi kết thúc)\n",
        "### Hướng giải quyết :\n",
        ">Trong solution này, nhóm tham khảo các thông tin được tác giả chia sẻ qua các discussion và các mô tả, notebook mà tác giả cung cấp. \n",
        "Với một số bước mà tác giả không giải thích rõ ràng hoặc các bước mà tác giả thừa kế, tham khảo lại từ người khác (cụ thể là những người tham gia vào cuộc thi này), nhóm em sẽ thừa kế và tìm hiểu các kết quả đó chứ không đi vào bước thực hiện cụ thể(đó là bước nào thì nhóm em sẽ nói rõ khi đi vào các bước ở bên dưới). \n",
        ">\n",
        ">Nhóm chọn tập trung vào một mô hình (cụ thể là XGB) trong 3 mô hình mà nhóm tác giả kết hợp để giải quyết. Trong quá trình code lại thì nhóm em cũng có điều chỉnh một số chỗ để code ngắn gọn và rõ ràng hơn (chỗ nào code lại hoàn toàn theo tác giả và chỗ nào code lại có điều chỉnh thì nhóm em đều có comment rõ ràng trong phần code ở bên dưới).\n",
        "\n",
        "**Tóm tắt cách giải quyết**\n",
        "- Thay vì dự đoán giao dịch gian lận thì chúng ta phát hiện khách hàng gian lận.\n",
        "#### 3 phần quan trọng trong solution :\n",
        "- [EDA for Columns V and ID](https://www.kaggle.com/cdeotte/eda-for-columns-v-and-id)\n",
        "- [Feature Engineering and Feature Selection](https://www.kaggle.com/c/ieee-fraud-detection/discussion/111308)\n",
        "- [The Magic Works](https://www.kaggle.com/cdeotte/xgb-fraud-with-magic-0-9600#How-the-Magic-Works)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tìm hiểu dữ liệu (Exploratory Data Analysis)\n",
        "\n"
      ],
      "metadata": {
        "id": "-N61oyLUWF4v"
      },
      "id": "-N61oyLUWF4v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhóm tác giả đã sử dụng kết quả [EDA của Alijs](https://www.kaggle.com/alijs1/ieee-transaction-columns-reference) (một người khác cũng tham gia vào cuộc thi) cho 53 cột thuộc tính #V và 95 cột V đầu tiên trong 339 cột V ban đầu.\n",
        "\n",
        "Với 339 cột thuộc tính V ,ta thực hiện giảm số lượng cột V cho mô hình:\n",
        "* Nhóm các cột có chung số lượng giá trị NAN với cột V \n",
        "* Chọn một tập con có kích thước tối đa gồm các cột không tương quan từ mỗi nhóm\n",
        "* Thay thế toàn bộ nhóm bằng tất cả các tập con của nó."
      ],
      "metadata": {
        "id": "gCjsqlB9euA3"
      },
      "id": "gCjsqlB9euA3"
    },
    {
      "cell_type": "markdown",
      "id": "8717feef",
      "metadata": {
        "id": "8717feef"
      },
      "source": [
        "### EDA for Columns V and ID\n",
        "Tác giả nhận thấy các cột thuộc tính V khá dư thừa, không đem lại nhiều thông tin mới và có tương quan (correlated) với nhau."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9574cb5",
      "metadata": {
        "id": "b9574cb5"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb494cd8",
      "metadata": {
        "id": "bb494cd8"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1x6xmQifUHQWZi7nDJs53do1G4q5aEnWI&export=download\n",
        "!unzip ieee-fraud-detection.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d22986f",
      "metadata": {
        "id": "2d22986f"
      },
      "source": [
        "#### Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ba5af2",
      "metadata": {
        "id": "b3ba5af2"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np,gc # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c49ce7",
      "metadata": {
        "id": "28c49ce7"
      },
      "outputs": [],
      "source": [
        "cols_t = ['TransactionID', 'TransactionDT', 'TransactionAmt',\n",
        "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
        "       'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
        "       'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
        "       'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8',\n",
        "       'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4',\n",
        "       'M5', 'M6', 'M7', 'M8', 'M9']\n",
        "cols_v = ['V'+str(x) for x in range(1,340)]; types_v = {}\n",
        "for c in cols_v: types_v[c] = 'float32'\n",
        "train = pd.read_csv('train_transaction.csv',usecols=cols_t+['isFraud']+cols_v,dtype=types_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581dbfb6",
      "metadata": {
        "id": "581dbfb6"
      },
      "source": [
        "#### NAN search\n",
        "Tìm kiếm tất cả các cột thuộc tính trong train_transaction.csv có số lượng giá trị NAN giống với các cột V , sau đó gom thành các block tương ứng với mỗi giá trị NAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e49e36",
      "metadata": {
        "id": "f5e49e36"
      },
      "outputs": [],
      "source": [
        "nans_df = train.isna()\n",
        "nans_groups={}\n",
        "i_cols = ['V'+str(i) for i in range(1,340)]\n",
        "for col in train.columns:\n",
        "    cur_group = nans_df[col].sum()\n",
        "    try:\n",
        "        nans_groups[cur_group].append(col)\n",
        "    except:\n",
        "        nans_groups[cur_group]=[col]\n",
        "del nans_df; x=gc.collect()\n",
        "\n",
        "for k,v in nans_groups.items():\n",
        "    print('####### NAN count =',k)\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theo như kết quả trên , ví dụ ở đây ta có được một số block như  D1 và [V281-V135] , D11 và [V1 - V11], hay các block gồm các cột V tương tự nhau về số lượng giá trị NAN như [V35 -V52]..."
      ],
      "metadata": {
        "id": "nNjqZZ6niexP"
      },
      "id": "nNjqZZ6niexP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Giảm số lượng cột V cho mỗi block"
      ],
      "metadata": {
        "id": "H2IehBkRntk2"
      },
      "id": "H2IehBkRntk2"
    },
    {
      "cell_type": "markdown",
      "id": "4eff1377",
      "metadata": {
        "id": "4eff1377"
      },
      "source": [
        "##### V1-V11,D11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75399c0",
      "metadata": {
        "id": "c75399c0"
      },
      "outputs": [],
      "source": [
        "Vc = ['dayr','isFraud','TransactionAmt','card1','addr1','D1n','D11n']\n",
        "Vs = nans_groups[279287]\n",
        "Vtitle = 'V1 - V11, D11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f36cb5",
      "metadata": {
        "id": "11f36cb5"
      },
      "outputs": [],
      "source": [
        "def make_plots(Vs):\n",
        "    col = 4\n",
        "    row = len(Vs)//4+1\n",
        "    plt.figure(figsize=(20,row*5))\n",
        "    idx = train[~train[Vs[0]].isna()].index\n",
        "    for i,v in enumerate(Vs):\n",
        "        plt.subplot(row,col,i+1)\n",
        "        n = train[v].nunique()\n",
        "        x = np.sum(train.loc[idx,v]!=train.loc[idx,v].astype(int))\n",
        "        y = np.round(100*np.sum(train[v].isna())/len(train),2)\n",
        "        t = 'int'\n",
        "        if x!=0: t = 'float'\n",
        "        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n",
        "        plt.yticks([])\n",
        "        h = plt.hist(train.loc[idx,v],bins=100)\n",
        "        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n",
        "    plt.show()\n",
        "make_plots(Vs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tính correlation giữa các cột V trong block."
      ],
      "metadata": {
        "id": "CnIYxgFRnSZO"
      },
      "id": "CnIYxgFRnSZO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2e4a21",
      "metadata": {
        "id": "ef2e4a21"
      },
      "outputs": [],
      "source": [
        "# Tính độ tương quan correlate giữa các cột thuộc tính\n",
        "def make_corr(Vs,Vtitle=''):\n",
        "    cols = ['TransactionDT'] + Vs\n",
        "    plt.figure(figsize=(15,15))\n",
        "    sns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n",
        "    if Vtitle!='': plt.title(Vtitle,fontsize=14)\n",
        "    else: plt.title(Vs[0]+' - '+Vs[-1],fontsize=14)\n",
        "    plt.show()\n",
        "make_corr(Vs,Vtitle)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong mỗi block, tiến hành giảm số lượng cột V trong block, bằng cách chỉ giữ lại cột V có nhiều giá trị nunique nhất trong mỗi nhóm correlated."
      ],
      "metadata": {
        "id": "kyE-Rbhkkwv4"
      },
      "id": "kyE-Rbhkkwv4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecc190b",
      "metadata": {
        "id": "4ecc190b"
      },
      "outputs": [],
      "source": [
        "grps = [[1],[2,3],[4,5],[6,7],[8,9],[10,11]]\n",
        "def reduce_group(grps,c='V'):\n",
        "    use = []\n",
        "    for g in grps:\n",
        "        mx = 0; vx = g[0]\n",
        "        for gg in g:\n",
        "            n = train[c+str(gg)].nunique()\n",
        "            if n>mx:\n",
        "                mx = n\n",
        "                vx = gg\n",
        "            #print(str(gg)+'-'+str(n),', ',end='')\n",
        "        use.append(vx)\n",
        "        #print()\n",
        "    print('Use these',use)\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59291c79",
      "metadata": {
        "id": "59291c79"
      },
      "source": [
        "##### V12 - V34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550e2f06",
      "metadata": {
        "id": "550e2f06"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[76073]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a7ee22",
      "metadata": {
        "id": "86a7ee22"
      },
      "outputs": [],
      "source": [
        "grps = [[12,13],[14],[15,16,17,18,21,22,31,32,33,34],[19,20],[23,24],[25,26],[27,28],[29,30]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64e95ef5",
      "metadata": {
        "id": "64e95ef5"
      },
      "source": [
        "##### V35 - V52"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d8fa585",
      "metadata": {
        "id": "8d8fa585"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[168969]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1dfccf6",
      "metadata": {
        "id": "c1dfccf6"
      },
      "outputs": [],
      "source": [
        "grps = [[35,36],[37,38],[39,40,42,43,50,51,52],[41],[44,45],[46,47],[48,49]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4022b574",
      "metadata": {
        "id": "4022b574"
      },
      "source": [
        "##### V53 - V74"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a5657e",
      "metadata": {
        "id": "90a5657e"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[77096]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e928ba59",
      "metadata": {
        "id": "e928ba59"
      },
      "outputs": [],
      "source": [
        "grps = [[53,54],[55,56],[57,58,59,60,63,64,71,72,73,74],[61,62],[65],[66,67],[68],[69,70]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cdd2151",
      "metadata": {
        "id": "6cdd2151"
      },
      "source": [
        "##### V75 - V94"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc886a2f",
      "metadata": {
        "id": "bc886a2f"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[89164]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15df4577",
      "metadata": {
        "id": "15df4577"
      },
      "outputs": [],
      "source": [
        "grps = [[75,76],[77,78],[79,80,81,84,85,92,93,94],[82,83],[86,87],[88],[89],[90,91]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9079d59",
      "metadata": {
        "id": "a9079d59"
      },
      "source": [
        "##### V95 - V137"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9115a63",
      "metadata": {
        "id": "a9115a63"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[314]\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74700a31",
      "metadata": {
        "id": "74700a31"
      },
      "outputs": [],
      "source": [
        "Vs = ['V'+str(x) for x in range(95,107)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbcdade1",
      "metadata": {
        "id": "bbcdade1"
      },
      "outputs": [],
      "source": [
        "grps = [[95,96,97,101,102,103,105,106],[98],[99,100],[104]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58feb42c",
      "metadata": {
        "id": "58feb42c"
      },
      "outputs": [],
      "source": [
        "Vs = ['V'+str(x) for x in range(107,124)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1758bbd4",
      "metadata": {
        "id": "1758bbd4"
      },
      "outputs": [],
      "source": [
        "grps = [[107],[108,109,110,114],[111,112,113],[115,116],[117,118,119],[120,122],[121],[123]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870b92db",
      "metadata": {
        "id": "870b92db"
      },
      "outputs": [],
      "source": [
        "Vs = ['V'+str(x) for x in range(124,138)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b577ab",
      "metadata": {
        "id": "b1b577ab"
      },
      "outputs": [],
      "source": [
        "grps = [[124,125],[126,127,128,132,133,134],[129],[130,131],[135,136,137]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077c01c3",
      "metadata": {
        "id": "077c01c3"
      },
      "source": [
        "##### V138 ~ V163"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a70d30",
      "metadata": {
        "id": "55a70d30"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[508595]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d48f1d",
      "metadata": {
        "id": "95d48f1d"
      },
      "outputs": [],
      "source": [
        "grps = [[138],[139,140],[141,142],[146,147],[148,149,153,154,156,157,158],[161,162,163]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b689dcd",
      "metadata": {
        "id": "7b689dcd"
      },
      "source": [
        "##### V143 ~ V166"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37a4134",
      "metadata": {
        "id": "f37a4134"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[508589]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59fb1e98",
      "metadata": {
        "id": "59fb1e98"
      },
      "outputs": [],
      "source": [
        "grps = [[143,164,165],[144,145,150,151,152,159,160],[166]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ded028c9",
      "metadata": {
        "id": "ded028c9"
      },
      "source": [
        "##### V167 ~ V216"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08b7081",
      "metadata": {
        "id": "b08b7081"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[450909]]\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e24829",
      "metadata": {
        "id": "56e24829"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[450909] if int(x[1:])<186]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71161e3d",
      "metadata": {
        "id": "71161e3d"
      },
      "outputs": [],
      "source": [
        "grps = [[167,168,177,178,179],[172,176],[173],[181,182,183]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad97f18a",
      "metadata": {
        "id": "ad97f18a"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[450909] if (int(x[1:])>183)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d034446",
      "metadata": {
        "id": "6d034446"
      },
      "outputs": [],
      "source": [
        "grps = [[186,187,190,191,192,193,196,199],[202,203,204,211,212,213],[205,206],[207],[214,215,216]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe35936",
      "metadata": {
        "id": "8fe35936"
      },
      "source": [
        "##### V169 ~ V210"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdff1b55",
      "metadata": {
        "id": "cdff1b55"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[450721]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb178f4",
      "metadata": {
        "id": "cfb178f4"
      },
      "outputs": [],
      "source": [
        "grps = [[169],[170,171,200,201],[174,175],[180],[184,185],[188,189],[194,195,197,198],[208,210],[209]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31f12b7",
      "metadata": {
        "id": "d31f12b7"
      },
      "source": [
        "##### V217 ~ V278"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0edb8da7",
      "metadata": {
        "id": "0edb8da7"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[460110]]\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4debcaa2",
      "metadata": {
        "id": "4debcaa2"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[460110] if int(x[1:])<240]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abaa1716",
      "metadata": {
        "id": "abaa1716"
      },
      "outputs": [],
      "source": [
        "grps = [[217,218,219,231,232,233,236,237],[223],[224,225],[226],[228],[229,230],[235]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9a502e",
      "metadata": {
        "id": "ef9a502e"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[460110] if (int(x[1:])>237)&(int(x[1:])<263)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4062d006",
      "metadata": {
        "id": "4062d006"
      },
      "outputs": [],
      "source": [
        "grps = [[240,241],[242,243,244,258],[246,257],[247,248,249,253,254],[252],[260],[261,262]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9127a119",
      "metadata": {
        "id": "9127a119"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[460110] if (int(x[1:])>262)]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989da055",
      "metadata": {
        "id": "989da055"
      },
      "outputs": [],
      "source": [
        "grps = [[263,265,264],[266,269],[267,268],[273,274,275],[276,277,278]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edef9ff",
      "metadata": {
        "id": "1edef9ff"
      },
      "source": [
        "##### V220 ~ V272"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f2478e",
      "metadata": {
        "id": "64f2478e"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[449124]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e845dc4c",
      "metadata": {
        "id": "e845dc4c"
      },
      "outputs": [],
      "source": [
        "grps = [[220],[221,222,227,245,255,256,259],[234],[238,239],[250,251],[270,271,272]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1eefd35",
      "metadata": {
        "id": "e1eefd35"
      },
      "source": [
        "##### V279 ~ V321"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d930494",
      "metadata": {
        "id": "2d930494"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[12]]\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1b0d6b",
      "metadata": {
        "id": "ed1b0d6b"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[12] if int(x[1:])<302]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab18666",
      "metadata": {
        "id": "eab18666"
      },
      "outputs": [],
      "source": [
        "grps = [[279,280,293,294,295,298,299],[284],[285,287],[286],[290,291,292],[297]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b7b04f",
      "metadata": {
        "id": "17b7b04f"
      },
      "outputs": [],
      "source": [
        "Vs = [x for x in nans_groups[12] if int(x[1:])>299]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aebe792",
      "metadata": {
        "id": "4aebe792"
      },
      "outputs": [],
      "source": [
        "grps = [[302,303,304],[305],[306,307,308,316,317,318],[309,311],[310,312],[319,320,321]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5fb6fd2",
      "metadata": {
        "id": "b5fb6fd2"
      },
      "source": [
        "##### V281 ~ V315, D1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "858440d1",
      "metadata": {
        "id": "858440d1"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[1269]\n",
        "make_plots(Vs)\n",
        "Vtitle = 'V281 - V315, D1'\n",
        "make_corr(Vs,Vtitle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cf3cac",
      "metadata": {
        "id": "a0cf3cac"
      },
      "outputs": [],
      "source": [
        "grps = [[281],[282,283],[288,289],[296],[300,301],[313,314,315]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e0f3fb",
      "metadata": {
        "id": "d7e0f3fb"
      },
      "source": [
        "##### V322 - V339"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd5d8f6",
      "metadata": {
        "id": "cbd5d8f6"
      },
      "outputs": [],
      "source": [
        "Vs = nans_groups[508189]\n",
        "make_plots(Vs)\n",
        "make_corr(Vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e02310",
      "metadata": {
        "id": "36e02310"
      },
      "outputs": [],
      "source": [
        "grps = [[322,323,324,326,327,328,329,330,331,332,333],[325],[334,335,336],[337,338,339]]\n",
        "reduce_group(grps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e52b747",
      "metadata": {
        "id": "1e52b747"
      },
      "source": [
        "#### Biểu diễn các cột thuộc tính"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### V reduced"
      ],
      "metadata": {
        "id": "cmsTTvKeuth1"
      },
      "id": "cmsTTvKeuth1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta còn lại 128 cột thuộc tính V"
      ],
      "metadata": {
        "id": "ZTGKReOxpGZk"
      },
      "id": "ZTGKReOxpGZk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1f7f3d",
      "metadata": {
        "id": "cf1f7f3d"
      },
      "outputs": [],
      "source": [
        "v =  [1, 3, 4, 6, 8, 11]\n",
        "v += [13, 14, 17, 20, 23, 26, 27, 30]\n",
        "v += [36, 37, 40, 41, 44, 47, 48]\n",
        "v += [54, 56, 59, 62, 65, 67, 68, 70]\n",
        "v += [76, 78, 80, 82, 86, 88, 89, 91]\n",
        "v += [96, 98, 99, 104]\n",
        "v += [107, 108, 111, 115, 117, 120, 121, 123]\n",
        "v += [124, 127, 129, 130, 136]\n",
        "v += [138, 139, 142, 147, 156, 162]\n",
        "v += [165, 160, 166]\n",
        "v += [178, 176, 173, 182]\n",
        "v += [187, 203, 205, 207, 215]\n",
        "v += [169, 171, 175, 180, 185, 188, 198, 210, 209]\n",
        "v += [218, 223, 224, 226, 228, 229, 235]\n",
        "v += [240, 258, 257, 253, 252, 260, 261]\n",
        "v += [264, 266, 267, 274, 277]\n",
        "v += [220, 221, 234, 238, 250, 271]\n",
        "v += [294, 284, 285, 286, 291, 297]\n",
        "v += [303, 305, 307, 309, 310, 320]\n",
        "v += [281, 283, 289, 296, 301, 314]\n",
        "v += [332, 325, 335, 338]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106a5798",
      "metadata": {
        "id": "106a5798"
      },
      "outputs": [],
      "source": [
        "print('Reduced set has',len(v),'columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc34dfae",
      "metadata": {
        "id": "fc34dfae"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + ['V'+str(x) for x in v]\n",
        "train2 = train[cols].sample(frac=0.2)\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train2[cols].corr(), cmap='RdBu_r', annot=False, center=0.0)\n",
        "plt.title('V1-V339 REDUCED',fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179d2ee3",
      "metadata": {
        "id": "179d2ee3"
      },
      "source": [
        "##### V all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633b821d",
      "metadata": {
        "id": "633b821d"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + ['V'+str(x) for x in range(1,340)]\n",
        "train2 = train[cols].sample(frac=0.2)\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train2[cols].corr(), cmap='RdBu_r', annot=False, center=0.0)\n",
        "plt.title('V1-V339 ALL',fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta có thể nhận thấy rằng 100 cột V đầu tiên không tương quan nhiều với 239 cột V cuối cùng. \n",
        "\n",
        "Ngoài ra, mặc dù có 6 nhóm NAN khác nhau trong 100 cột V đầu tiên nhưng có nhiều mối tương quan giữa các nhóm này ; tương tự, 239 cột V sau có liên quan đến nhau."
      ],
      "metadata": {
        "id": "Ca_5ij7Mqh3B"
      },
      "id": "Ca_5ij7Mqh3B"
    },
    {
      "cell_type": "markdown",
      "id": "5a023fd8",
      "metadata": {
        "id": "5a023fd8"
      },
      "source": [
        "##### C columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4bc7a3",
      "metadata": {
        "id": "6c4bc7a3"
      },
      "outputs": [],
      "source": [
        "def make_plots2(Vs):\n",
        "    col = 4\n",
        "    row = len(Vs)//4+1\n",
        "    plt.figure(figsize=(20,row*5))\n",
        "    for i,v in enumerate(Vs):\n",
        "        plt.subplot(row,col,i+1)\n",
        "        idx = train[~train[v].isna()].index\n",
        "        n = train[v].nunique()\n",
        "        x = np.sum(train.loc[idx,v]!=train.loc[idx,v].astype(int))\n",
        "        y = np.round(100*np.sum(train[v].isna())/len(train),2)\n",
        "        t = 'int'\n",
        "        if x!=0: t = 'float'\n",
        "        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n",
        "        plt.yticks([])\n",
        "        h = plt.hist(train.loc[idx,v],bins=100)\n",
        "        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n",
        "    plt.show()\n",
        "make_plots2(['C'+str(x) for x in range(1,15)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff4e080",
      "metadata": {
        "id": "9ff4e080"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + ['C'+str(x) for x in range(1,15)]\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n",
        "plt.title('C1-C15')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d29b394",
      "metadata": {
        "id": "1d29b394"
      },
      "source": [
        "##### D Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca759c9f",
      "metadata": {
        "id": "ca759c9f"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + ['D'+str(x) for x in range(1,16)]\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n",
        "plt.title('D1-D15')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5e6c27",
      "metadata": {
        "id": "0d5e6c27"
      },
      "source": [
        "##### M Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9606ac8",
      "metadata": {
        "id": "a9606ac8"
      },
      "outputs": [],
      "source": [
        "Ms = ['M'+str(x) for x in range(1,10)]\n",
        "mp = {'F':0,'T':1,'M0':0,'M1':1,'M2':2}\n",
        "for c in Ms: train[c] = train[c].map(mp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25bd01d2",
      "metadata": {
        "id": "25bd01d2"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + Ms\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n",
        "plt.title('M1-M9')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3252b3a9",
      "metadata": {
        "id": "3252b3a9"
      },
      "source": [
        "##### ID Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e7bb56",
      "metadata": {
        "id": "26e7bb56"
      },
      "outputs": [],
      "source": [
        "train_id = pd.read_csv('train_identity.csv')\n",
        "train_id = pd.merge(train_id,train[['TransactionID','TransactionDT']],on='TransactionID',how='left')\n",
        "ids = ['id_0'+str(x) for x in range(1,10)]+['id_'+str(x) for x in range(10,39)]\n",
        "for c in ids: print (c,train_id[c].unique()[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704aefa1",
      "metadata": {
        "id": "704aefa1"
      },
      "outputs": [],
      "source": [
        "booln = ['id_12','id_15','id_16','id_27','id_28','id_29','id_35','id_36','id_37','id_38']\n",
        "cats = ['id_23','id_30','id_31','id_33','id_34']\n",
        "mp = {'Unknown':0,'NotFound':1,'Found':2,'New':3,'F':0,'T':1}\n",
        "for c in booln: train_id[c] = train_id[c].map(mp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1efd89",
      "metadata": {
        "id": "5f1efd89"
      },
      "outputs": [],
      "source": [
        "def make_plots2(Vs):\n",
        "    col = 4\n",
        "    row = len(Vs)//4+1\n",
        "    plt.figure(figsize=(20,row*5))\n",
        "    for i,v in enumerate(Vs):\n",
        "        plt.subplot(row,col,i+1)\n",
        "        idx = train_id[~train_id[v].isna()].index\n",
        "        n = train_id[v].nunique()\n",
        "        x = np.sum(train_id.loc[idx,v]!=train_id.loc[idx,v].astype(int))\n",
        "        y = np.round(100*np.sum(train_id[v].isna())/len(train_id),2)\n",
        "        t = 'int'\n",
        "        if x!=0: t = 'float'\n",
        "        plt.title(v+' has '+str(n)+' '+t+' and '+str(y)+'% nan')\n",
        "        plt.yticks([])\n",
        "        h = plt.hist(train_id.loc[idx,v],bins=100)\n",
        "        if len(h[0])>1: plt.ylim((0,np.sort(h[0])[-2]))\n",
        "    plt.show()\n",
        "make_plots2([x for x in ids if x not in cats])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27c3f9e",
      "metadata": {
        "id": "e27c3f9e"
      },
      "outputs": [],
      "source": [
        "cols = ['TransactionDT'] + [x for x in ids if x not in cats]\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(train_id[cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\n",
        "plt.title('ID1-ID38')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering and Feature Selection"
      ],
      "metadata": {
        "id": "wnCpUgwTwEou"
      },
      "id": "wnCpUgwTwEou"
    },
    {
      "cell_type": "markdown",
      "id": "f0f813e0",
      "metadata": {
        "id": "f0f813e0"
      },
      "source": [
        "Dưới đây là một số ý tưởng về cách tạo mới và chọn thuộc tính cho mô hình mà nhóm tác giả đã thực hiện:\n",
        ">Kernel https://www.kaggle.com/kyakovlev/ieee-fe-for-local-test của Konstantin thực hiện các FE for local test và chứng minh các kỹ thuật đó. Mọi người có thể xem để tham khảo thêm\n",
        "1. Tạo một feature mới và sau đó đánh giá nó bằng các tiến hành xác thực cục bộ (local validation scheme)  để xem liệu nó có cải thiện CV của mô hình hay không. Giữ lại các feature có lợi và loại bỏ các feature khác.\n",
        "2. Lựa chọn các thuộc tính chuyển tiếp (sử dụng trên một thuộc tính hoặc nhóm các thuộc tính)\n",
        "3. Loại bỏ thuộc tính đệ quy (sử dụng cho một thuộc tính hoặc nhóm các thuộc tính).\n",
        "4. Xác đinh tầm quan trọng của thuộc tính bằng cách thực hiện hoán vị các giá trị thuộc tính.\n",
        "5. Xác thực chéo.\n",
        "6. Phân tích tương quan các thuộc tính.\n",
        "7. Tính nhất quán về thời gian.\n",
        "8. Tính nhất quán của khách hàng.\n",
        "9. Xem xét sự phân phối của tập dữ liệu thử nghiệm so với tập dữ liệu đào tạo và xem chúng giống và khác nhau như thế nào."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train & Test"
      ],
      "metadata": {
        "id": "0Xf0vubGDt_V"
      },
      "id": "0Xf0vubGDt_V"
    },
    {
      "cell_type": "markdown",
      "id": "cb95f30d",
      "metadata": {
        "id": "cb95f30d"
      },
      "source": [
        ">Khi thực hiện mã hóa nhãn, phải mã hóa trên cùng tập dữ liệu Train và Test bằng cách gộp chung dữ liệu lại với nhau.\n",
        "\n",
        "```python\n",
        "    df = pd.concat([train[col],test[col]],axis=0) \n",
        "    # PERFORM FEATURE ENGINEERING HERE\n",
        "    train[col] = df[:len(train)]   \n",
        "    test[col] = df[len(train):]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xử lý giá trị NAN - NAN Processing"
      ],
      "metadata": {
        "id": "McJiqwHzDgmB"
      },
      "id": "McJiqwHzDgmB"
    },
    {
      "cell_type": "markdown",
      "id": "3e921123",
      "metadata": {
        "id": "3e921123"
      },
      "source": [
        "\n",
        ">Nếu ta cung cấp giá trị np.nan cho mô hình, thì tại mỗi lần Tree phân chia, nó sẽ tách các giá trị không phải NAN và sau đó gửi tất cả các NAN đến con trái hoặc con phải tùy thuộc vào điều gì tốt nhất. Do đó, các giá trị NAN được đối xử đặc biệt ở mọi node và có thể trở dẫn đến overfit.\n",
        ">\n",
        ">-->Chuyển đổi tất cả NAN thành một số âm thấp hơn tất cả các giá trị không phải NAN (chẳng hạn như - 999) thì mô hình sẽ không ưu tiên xử lý với NAN nữa và dành cho nó sự chú ý giống như những con số khác.Trong bài này tác giả sử dụng giá trị -1   \n",
        "```python\n",
        "df[col].fillna(-999, inplace=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Label Encode/ Factorize/ Memory reduction"
      ],
      "metadata": {
        "id": "rr82l9O6Dy4A"
      },
      "id": "rr82l9O6Dy4A"
    },
    {
      "cell_type": "markdown",
      "id": "0a429f3a",
      "metadata": {
        "id": "0a429f3a"
      },
      "source": [
        ">Mã hóa nhãn ,chuyển đổi một cột thuộc tính kiểu string, category, object thành kiểu integers. Sau đó, ta có thể chuyển thành kiểu int8, int16 hoặc int32 tùy thuộc vào việc kiểm tra giá trị lớn nhất của cột. Từ đó giúp giảm bộ nhớ lưu trữ và biến các giá trị NAN thành một số.\n",
        "```python\n",
        "df[col],_ = df[col].factorize() #factorize() function encode the object as an enumerated type or categorical variable.\n",
        "if df[col].max()<128: df[col] = df[col].astype('int8')\n",
        "elif df[col].max()<32768: df[col] = df[col].astype('int16')\n",
        "else: df[col].astype('int32')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2bfba40",
      "metadata": {
        "id": "b2bfba40"
      },
      "source": [
        ">Ngoài ra để giảm bộ nhớ, ta sử dụng memory_reducer trên các cột. Một cách tiếp cận đơn giản và an toàn hơn là chuyển đổi tất cả các giá trị kiểu float64 thành float32 và tất cả giá trị kiểu int64 thành int32. (Tốt nhất nên tránh float16 , sử dụng int8 và int16 nếu muốn).\n",
        "```python\n",
        "for col in df.columns:\n",
        "    if df[col].dtype=='float64': df[col] = df[col].astype('float32')\n",
        "    if df[col].dtype=='int64': df[col] = df[col].astype('int32')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Thuộc tính phân loại - Categorical Features"
      ],
      "metadata": {
        "id": "PAJ_4yD5DOPV"
      },
      "id": "PAJ_4yD5DOPV"
    },
    {
      "cell_type": "markdown",
      "id": "94535d2d",
      "metadata": {
        "id": "94535d2d"
      },
      "source": [
        "\n",
        ">Với các biến phân loại, nếu ta đã mã hóa các nhãn trước đó, ta sẽ để mô hình xem xét một thuộc tính nào đó nếu thuộc kiểu 'categorical' hay 'numeric' thì tốt hơn đối với mô hình. Từ đó quyết định thuộc tính nào tốt nhất dưới dạng số và tính năng nào tốt nhất ở dạng phân loại. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chia tách - Splitting"
      ],
      "metadata": {
        "id": "ImYynVL9DKfz"
      },
      "id": "ImYynVL9DKfz"
    },
    {
      "cell_type": "markdown",
      "id": "200dbe32",
      "metadata": {
        "id": "200dbe32"
      },
      "source": [
        ">Một cột kiểu string/numeric có thể được tách thành hai cột mới.\n",
        ">\n",
        ">Ví dụ, một cột feature kiểu string chẳng hạn như cột 'id_30' có gí trị “ Mac OS X 10_9_5”  có thể được chia thành 2 cột mới là:\n",
        ">1. \"Operating System\"  có giá trị \"Mac OS X” \n",
        ">2. \"Version\" có giá trị là  “10_9_5”. \n",
        ">\n",
        ">Hoặc ví dụ với cột feature là \"TransactionAmt\" kiểu numeric có giá trị “ 1230.45” có thể được tách thành 2 cột ( tức là 2 feature mới) :\n",
        ">1. \"USD\" có giá trị  “ 1230” \n",
        ">2. \"Cent\" có giá trị  “ 45”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combining / Transforming / Interaction"
      ],
      "metadata": {
        "id": "ha1LTiCoD41y"
      },
      "id": "ha1LTiCoD41y"
    },
    {
      "cell_type": "markdown",
      "id": "9c1ae778",
      "metadata": {
        "id": "9c1ae778"
      },
      "source": [
        "Hai cột có kiểu string/ numeric có thể được kết hợp thành một cột mới. \n",
        "\n",
        ">Ví dụ cột feature \"card1\" và feature \"card2\" có thể trở thành một cột feature mới là \"uid\"\n",
        "```python\n",
        "df['uid'] = df[‘card1’].astype(str)+’_’+df[‘card2’].astype(str)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0dfbd1d",
      "metadata": {
        "id": "a0dfbd1d"
      },
      "source": [
        ">Điều này giúp ích cho mô hình bởi vì bản thân thuộc tính 'card1' và 'card2' có thể không tương quan với target của bài toán ,do đó mô hình sẽ không phân chia các thuộc tính này. Nhưng thuộc tính 'uid = card1_card2' có thể tương quan với target và bây giờ mô hình có thể sử dụng thuộc tính này.\n",
        ">\n",
        "> Các cột thuộc tính kiểu số - numeric có thể được kết hợp với nhau bằng các phép cộng, trừ, nhân, v.v. \n",
        ">\n",
        ">ví dụ:\n",
        "```python\n",
        " df['x1_x2'] = df['x1'] * df['x2']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mã hóa tần suất - Frequency Encoding"
      ],
      "metadata": {
        "id": "DsYRqzCdCzDW"
      },
      "id": "DsYRqzCdCzDW"
    },
    {
      "cell_type": "markdown",
      "id": "f0d58dbd",
      "metadata": {
        "id": "f0d58dbd"
      },
      "source": [
        "\n",
        ">Mã hóa tần số là một kỹ thuật mạnh mẽ cho phép mô hình \"nhìn thấy\" liệu các giá trị nào đó của thuộc tính là hiếm gặp hay phổ biến. \n",
        ">\n",
        ">Ví dụ: nếu muốn mô hình nhân ra thuộc tính \"credit_card\" nào được sử dụng thường xuyên t có thể tiến hành đếm tần số xuất hiện của tất cả các giá trị cột \"card1\":\n",
        "```python\n",
        "temp = df['card1'].value_counts().to_dict()\n",
        "df['card1_counts'] = df['card1'].map(temp)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tổng hợp/ thống kê nhóm - Aggregations / Group Statistics"
      ],
      "metadata": {
        "id": "nm4QgonbC5qI"
      },
      "id": "nm4QgonbC5qI"
    },
    {
      "cell_type": "markdown",
      "id": "8e3d71c0",
      "metadata": {
        "id": "8e3d71c0"
      },
      "source": [
        ">Cung cấp cho mô hình các thông kê giá trị theo nhóm thuộc tính cho phép mô hình xác định xem giá trị nào là phổ biến hay hiếm gặp đối với từng nhóm thuộc tính cụ thể.\n",
        "```python\n",
        "temp = df.groupby('card1')['TransactionAmt'].agg(['mean'])   \n",
        "    .rename({'mean':'TransactionAmt_card1_mean'},axis=1)\n",
        "df = pd.merge(df,temp,on='card1',how='left')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chuẩn hóa - Normalize / Standardize"
      ],
      "metadata": {
        "id": "l6qa8N4RC8kv"
      },
      "id": "l6qa8N4RC8kv"
    },
    {
      "cell_type": "markdown",
      "id": "06bf7797",
      "metadata": {
        "id": "06bf7797"
      },
      "source": [
        ">Chuẩn hóa các cột so với chính chúng. Hoặc chuẩn hóa cột này so với một cột khác.\n",
        "\n",
        "```python\n",
        "    #themselfs \n",
        "    df[col] = ( df[col]-df[col].mean() ) / df[col].std()\n",
        "    #normalize D3 -> loại bỏ sự phụ thuộc theo thời gian\n",
        "    df['D3_remove_time'] = df['D3'] - df['D3_week_mean']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outlier Removal / Relax / Smooth / PCA"
      ],
      "metadata": {
        "id": "6rVLG9fkDET8"
      },
      "id": "6rVLG9fkDET8"
    },
    {
      "cell_type": "markdown",
      "id": "7c341ba3",
      "metadata": {
        "id": "7c341ba3"
      },
      "source": [
        ">Trong cuộc thi này, tác giả muốn tìm ra điểm bất thường nên tg sử dụng kỹ thuật làm mịn một cách cẩn thận.\n",
        ">\n",
        ">Loại bỏ ngoại lệ -ý tưởng : xác định và thay thế các giá trị không phổ biến.\n",
        ">\n",
        ">Ví dụ: bằng cách sử dụng mã hóa tần suất cho một biến thuộc tính, ta có thể loại bỏ tất cả các giá trị xuất hiện dưới 0,1% bằng cách thay thế chúng bằng một giá trị mới như -9999. (khác giá trị thay cho NAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db00efb",
      "metadata": {
        "id": "8db00efb"
      },
      "source": [
        "### Các bước thực hiện"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "429e4862",
      "metadata": {
        "id": "429e4862"
      },
      "source": [
        "#### Load Data\n",
        ">Nhóm tg load tất cả data ngoại trừ 229 V columns đã được tác giả xác định dư thừa thông qua phân tích tương quan như ở trên."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7490518",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-12-01T14:38:22.959515Z",
          "iopub.status.busy": "2021-12-01T14:38:22.957329Z",
          "iopub.status.idle": "2021-12-01T14:38:24.899590Z",
          "shell.execute_reply": "2021-12-01T14:38:24.898558Z",
          "shell.execute_reply.started": "2021-12-01T14:38:22.959375Z"
        },
        "id": "c7490518"
      },
      "outputs": [],
      "source": [
        "BUILD95 = True\n",
        "BUILD96 = True\n",
        "\n",
        "import numpy as np, pandas as pd, os, gc\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# COLUMNS WITH STRINGS\n",
        "str_type = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain','M1', 'M2', 'M3', 'M4','M5',\n",
        "            'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', \n",
        "            'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\n",
        "str_type += ['id-12', 'id-15', 'id-16', 'id-23', 'id-27', 'id-28', 'id-29', 'id-30', \n",
        "            'id-31', 'id-33', 'id-34', 'id-35', 'id-36', 'id-37', 'id-38']\n",
        "\n",
        "# FIRST 53 COLUMNS\n",
        "cols = ['TransactionID', 'TransactionDT', 'TransactionAmt',\n",
        "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
        "       'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
        "       'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
        "       'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8',\n",
        "       'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4',\n",
        "       'M5', 'M6', 'M7', 'M8', 'M9']\n",
        "\n",
        "# V COLUMNS TO LOAD DECIDED BY CORRELATION EDA\n",
        "\n",
        "cols += ['V'+str(x) for x in v]\n",
        "dtypes = {}\n",
        "for c in cols+['id_0'+str(x) for x in range(1,10)]+['id_'+str(x) for x in range(10,34)]+\\\n",
        "    ['id-0'+str(x) for x in range(1,10)]+['id-'+str(x) for x in range(10,34)]:\n",
        "        dtypes[c] = 'float32'\n",
        "for c in str_type: dtypes[c] = 'category'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c79e736",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-01T14:38:24.903125Z",
          "iopub.status.busy": "2021-12-01T14:38:24.902587Z",
          "iopub.status.idle": "2021-12-01T14:39:14.953612Z",
          "shell.execute_reply": "2021-12-01T14:39:14.952660Z",
          "shell.execute_reply.started": "2021-12-01T14:38:24.902913Z"
        },
        "id": "4c79e736"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# LOAD TRAIN\n",
        "X_train = pd.read_csv('train_transaction.csv',index_col='TransactionID', dtype=dtypes, usecols=cols+['isFraud'])\n",
        "train_id = pd.read_csv('train_identity.csv',index_col='TransactionID', dtype=dtypes)\n",
        "X_train = X_train.merge(train_id, how='left', left_index=True, right_index=True)\n",
        "# LOAD TEST\n",
        "X_test = pd.read_csv('test_transaction.csv',index_col='TransactionID', dtype=dtypes, usecols=cols)\n",
        "test_id = pd.read_csv('test_identity.csv',index_col='TransactionID', dtype=dtypes)\n",
        "fix = {o:n for o, n in zip(test_id.columns, train_id.columns)}\n",
        "test_id.rename(columns=fix, inplace=True)\n",
        "X_test = X_test.merge(test_id, how='left', left_index=True, right_index=True)\n",
        "# TARGET\n",
        "y_train = X_train['isFraud'].copy()\n",
        "del train_id, test_id, X_train['isFraud']; x = gc.collect()\n",
        "# PRINT STATUS\n",
        "print('Train shape',X_train.shape,'test shape',X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chuẩn hóa các cột thuộc tính D"
      ],
      "metadata": {
        "id": "BjkyH7_bEmT-"
      },
      "id": "BjkyH7_bEmT-"
    },
    {
      "cell_type": "markdown",
      "id": "f6ddb099",
      "metadata": {
        "id": "f6ddb099"
      },
      "source": [
        "Công thức chuẩn hóa cho các giá trị cột D như sau:\n",
        "\n",
        " `D15n = Transaction_Day - D15`\n",
        " \n",
        " `Transaction_Day = TransactionDT/(24*60*60)`. \n",
        " \n",
        "D Columns là các khoảng thời gian được tính từ 1 thời điểm nào đó trong quá khứ. Nhóm tiến hành transform các cột D thành các ngày cụ thể trong quá khứ. Loại bỏ sự phụ thuộc theo thời gian (dây ko còn là bài toán time series) giá trị của các features D không còn tăng dần theo thời gian nữa.\n",
        "\n",
        "Ngoài ra, các thuộc tính D*n giúp mô hình phân loại tốt hơn, sẽ được nói cụ thể ở dưới."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b5ad27",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-01T14:39:14.955076Z",
          "iopub.status.busy": "2021-12-01T14:39:14.954823Z",
          "iopub.status.idle": "2021-12-01T14:39:21.804260Z",
          "shell.execute_reply": "2021-12-01T14:39:21.803362Z",
          "shell.execute_reply.started": "2021-12-01T14:39:14.955031Z"
        },
        "id": "18b5ad27"
      },
      "outputs": [],
      "source": [
        "# PLOT ORIGINAL D\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.scatter(X_train.TransactionDT,X_train.D15)\n",
        "plt.title('Original D15')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('D15')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aee54e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-01T14:39:21.805751Z",
          "iopub.status.busy": "2021-12-01T14:39:21.805500Z",
          "iopub.status.idle": "2021-12-01T14:39:21.860290Z",
          "shell.execute_reply": "2021-12-01T14:39:21.857811Z",
          "shell.execute_reply.started": "2021-12-01T14:39:21.805709Z"
        },
        "id": "7aee54e2"
      },
      "outputs": [],
      "source": [
        "# NORMALIZE D COLUMNS\n",
        "for i in range(1,16):\n",
        "    if i in [1,2,3,5,9]: continue\n",
        "    X_train['D'+str(i)] =  X_train['D'+str(i)] - X_train.TransactionDT/np.float32(24*60*60)\n",
        "    X_test['D'+str(i)] = X_test['D'+str(i)] - X_test.TransactionDT/np.float32(24*60*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d94db5",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.861466Z",
          "iopub.status.idle": "2021-12-01T14:39:21.861989Z"
        },
        "id": "96d94db5"
      },
      "outputs": [],
      "source": [
        "# PLOT TRANSFORMED D\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.scatter(X_train.TransactionDT,X_train.D15)\n",
        "plt.title('Transformed D15')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('D15n')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5fd477",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.863116Z",
          "iopub.status.idle": "2021-12-01T14:39:21.863525Z"
        },
        "id": "de5fd477"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Mã hóa nhãn (label encode) và thực hiện giảm bộ nhớ.\n",
        "for i,f in enumerate(X_train.columns):\n",
        "    # Đối với các biến thuộc tính phân loại:\n",
        "    if (np.str(X_train[f].dtype)=='category')|(X_train[f].dtype=='object'): \n",
        "        df_comb = pd.concat([X_train[f],X_test[f]],axis=0) #nối dữ liệu train và test lại với nhau\n",
        "        df_comb,_ = df_comb.factorize(sort=True)   # mã hóa và xáo trôn thứ tự dữ liệu\n",
        "        if df_comb.max()>32000: print(f,'needs int32') #kiểm tra giá trị max để astype kiểu phù hợp\n",
        "        X_train[f] = df_comb[:len(X_train)].astype('int16')\n",
        "        X_test[f] = df_comb[len(X_train):].astype('int16')\n",
        "    # SHIFT ALL NUMERICS POSITIVE. SET NAN to -1\n",
        "    elif f not in ['TransactionAmt','TransactionDT']:\n",
        "        mn = np.min((X_train[f].min(),X_test[f].min()))\n",
        "        X_train[f] -= np.float32(mn)\n",
        "        X_test[f] -= np.float32(mn)\n",
        "        X_train[f].fillna(-1,inplace=True)\n",
        "        X_test[f].fillna(-1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Các bước mã hóa"
      ],
      "metadata": {
        "id": "JQgMffCXIdkg"
      },
      "id": "JQgMffCXIdkg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. `encode_FE` : hàm này thực hiện frequency encode- mã hóa tần suất cho giá trị của các thuộc tính, trong đó ta cần kết hợp dữ liệu train và test trước khi thực hiện mã hóa.\n",
        "* Input : dữ liệu train, test, các cột thuộc tính cần mã hóa\n",
        "* Output: tạo thêm một cột thuộc tính mới - là tần suất của các giá trị trương ứng trong cột thuộc tính input đầu vào."
      ],
      "metadata": {
        "id": "_EctA4oGIj3J"
      },
      "id": "_EctA4oGIj3J"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mã hóa tần số cho thuộc tính\n",
        "def encode_FE(df1, df2, cols):\n",
        "    for col in cols:\n",
        "        df = pd.concat([df1[col],df2[col]])\n",
        "        vc = df.value_counts(dropna=True, normalize=True).to_dict()\n",
        "        vc[-1] = -1\n",
        "        nm = col+'_FE'\n",
        "        df1[nm] = df1[col].map(vc)\n",
        "        df1[nm] = df1[nm].astype('float32')\n",
        "        df2[nm] = df2[col].map(vc)\n",
        "        df2[nm] = df2[nm].astype('float32')\n",
        "        print(nm,', ',end='')"
      ],
      "metadata": {
        "id": "S05rHQ53IqbG"
      },
      "id": "S05rHQ53IqbG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. `encode_LE` : mã hóa nhãn cho các thuộc tính phân loại thành kiểu số nguyên."
      ],
      "metadata": {
        "id": "GYzDUAIoIuHq"
      },
      "id": "GYzDUAIoIuHq"
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL ENCODE\n",
        "def encode_LE(col,train=X_train,test=X_test,verbose=True):\n",
        "    df_comb = pd.concat([train[col],test[col]],axis=0)\n",
        "    df_comb,_ = df_comb.factorize(sort=True)\n",
        "    nm = col\n",
        "    if df_comb.max()>32000: \n",
        "        train[nm] = df_comb[:len(train)].astype('int32')\n",
        "        test[nm] = df_comb[len(train):].astype('int32')\n",
        "    else:\n",
        "        train[nm] = df_comb[:len(train)].astype('int16')\n",
        "        test[nm] = df_comb[len(train):].astype('int16')\n",
        "    del df_comb; x=gc.collect()\n",
        "    if verbose: print(nm,', ',end='')"
      ],
      "metadata": {
        "id": "7Td_cW64IzMI"
      },
      "id": "7Td_cW64IzMI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.`encode_AG` : tạo các thuộc tính tổng hợp ( theo giá trị trung bình - mean hoặc độ lệch chuẩn - std ) bằng cách thống kê theo nhóm thuộc tính."
      ],
      "metadata": {
        "id": "1U6hx-9kI4TS"
      },
      "id": "1U6hx-9kI4TS"
    },
    {
      "cell_type": "code",
      "source": [
        "# GROUP AGGREGATION MEAN AND STD\n",
        "def encode_AG(main_columns, uids, aggregations=['mean'], train_df=X_train, test_df=X_test, \n",
        "              fillna=True, usena=False):\n",
        "    # AGGREGATION OF MAIN WITH UID FOR GIVEN STATISTICS #thống kê theo uid\n",
        "    for main_column in main_columns: \n",
        "        for col in uids:\n",
        "            for agg_type in aggregations:\n",
        "                new_col_name = main_column+'_'+col+'_'+agg_type\n",
        "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]]) #concat new feature\n",
        "                if usena: temp_df.loc[temp_df[main_column]==-1,main_column] = np.nan #thay nan vào các gt=-1 (đã đc xử lí trước đó)\n",
        "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
        "                                                        columns={agg_type: new_col_name})  \n",
        "\n",
        "                temp_df.index = list(temp_df[col]) #set index by uid\n",
        "                temp_df = temp_df[new_col_name].to_dict() # convert to dict \n",
        "\n",
        "                train_df[new_col_name] = train_df[col].map(temp_df).astype('float32')  # map mean_value\n",
        "                test_df[new_col_name]  = test_df[col].map(temp_df).astype('float32')   # map mean_value\n",
        "                \n",
        "                if fillna:\n",
        "                    train_df[new_col_name].fillna(-1,inplace=True)\n",
        "                    test_df[new_col_name].fillna(-1,inplace=True)\n",
        "                \n",
        "                print(\"'\"+new_col_name+\"'\",', ',end='')\n",
        "                "
      ],
      "metadata": {
        "id": "yg0lCfhhJDA_"
      },
      "id": "yg0lCfhhJDA_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. `encode_CB` : tạo các thuộc tính mới cho mô hình bằng cách kết hợp các thuộc tính lại với nhau. "
      ],
      "metadata": {
        "id": "dwnEeVhVJFXS"
      },
      "id": "dwnEeVhVJFXS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d77b3d",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.864454Z",
          "iopub.status.idle": "2021-12-01T14:39:21.865081Z"
        },
        "id": "11d77b3d"
      },
      "outputs": [],
      "source": [
        "# COMBINE FEATURES (create newfeaturé from 2 colums, then encode label for new_feature)\n",
        "def encode_CB(col1,col2,df1=X_train,df2=X_test):\n",
        "    nm = col1+'_'+col2\n",
        "    df1[nm] = df1[col1].astype(str)+'_'+df1[col2].astype(str) # kết hợp để tạo feature mới\n",
        "    df2[nm] = df2[col1].astype(str)+'_'+df2[col2].astype(str) # kết hợp ............\n",
        "    encode_LE(nm,verbose=False) #mã háo nhãn  cho feature mới\n",
        "    print(nm,', ',end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.`encode_AG2`: tạo các thuộc tính tổng hợp với giá trị duy nhất - thống kê số các giá trị khác nhau của mỗi nhóm thuộc tính tổng hợp."
      ],
      "metadata": {
        "id": "jnua6ENUJUou"
      },
      "id": "jnua6ENUJUou"
    },
    {
      "cell_type": "code",
      "source": [
        "# GROUP AGGREGATION NUNIQUE\n",
        "def encode_AG2(main_columns, uids, train_df=X_train, test_df=X_test):\n",
        "    for main_column in main_columns:  \n",
        "        for col in uids:\n",
        "            comb = pd.concat([train_df[[col]+[main_column]],test_df[[col]+[main_column]]],axis=0)\n",
        "            mp = comb.groupby(col)[main_column].agg(['nunique'])['nunique'].to_dict()\n",
        "            train_df[col+'_'+main_column+'_ct'] = train_df[col].map(mp).astype('float32')\n",
        "            test_df[col+'_'+main_column+'_ct'] = test_df[col].map(mp).astype('float32')\n",
        "            print(col+'_'+main_column+'_ct, ',end='')"
      ],
      "metadata": {
        "id": "3KQLmj-XJL4P"
      },
      "id": "3KQLmj-XJL4P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f2ae5e41",
      "metadata": {
        "id": "f2ae5e41"
      },
      "source": [
        "#### Feature Engineering\n",
        "Quy trình: Đầu tiên cần có ý tưởng tạo một feature mới. Sau đó, thêm nó vào mô hình của mình và đánh giá xem AUC tăng hay giảm. Nếu AUC tăng, giữ lại , nếu không thì loại bỏ.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9b2726",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.866310Z",
          "iopub.status.idle": "2021-12-01T14:39:21.866904Z"
        },
        "id": "de9b2726"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%time\n",
        "# TRANSACTION AMT CENTS \n",
        "X_train['cents'] = (X_train['TransactionAmt'] - np.floor(X_train['TransactionAmt'])).astype('float32')  #làm tròn\n",
        "X_test['cents'] = (X_test['TransactionAmt'] - np.floor(X_test['TransactionAmt'])).astype('float32') #làm tròn\n",
        "print('cents, ', end='')\n",
        "# FREQUENCY ENCODE: ADDR1, CARD1, CARD2, CARD3, P_EMAILDOMAIN #mã hóa tần suất cho các cột thuộc tính\n",
        "encode_FE(X_train,X_test,['addr1','card1','card2','card3','P_emaildomain'])\n",
        "# COMBINE COLUMNS CARD1+ADDR1, CARD1+ADDR1+P_EMAILDOMAIN  #Tạo thuộc tính mới\n",
        "encode_CB('card1','addr1')\n",
        "encode_CB('card1_addr1','P_emaildomain')\n",
        "# FREQUENCY ENOCDE # mã hóa tần suất cho các thuộc tính mới\n",
        "encode_FE(X_train,X_test,['card1_addr1','card1_addr1_P_emaildomain'])\n",
        "# GROUP AGGREGATE #\n",
        "encode_AG(['TransactionAmt','D9','D11'],['card1','card1_addr1','card1_addr1_P_emaildomain'],['mean','std'],usena=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tất cả 28 features mới này được chọn bởi vì mỗi features làm tăng giá trị local validation."
      ],
      "metadata": {
        "id": "Orm8kqhRJGxY"
      },
      "id": "Orm8kqhRJGxY"
    },
    {
      "cell_type": "markdown",
      "id": "f3d3c3c1",
      "metadata": {
        "id": "f3d3c3c1"
      },
      "source": [
        "#### Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tính nhất quán về thời gian"
      ],
      "metadata": {
        "id": "fNRmG9fpN7ZI"
      },
      "id": "fNRmG9fpN7ZI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhóm tg đã thêm 28 features mới ở trên. Vì vậy,hiện tại chúng ta có 242 features. Bây giờ ta sẽ kiểm tra từng feature để theo dõi tính nhất quán về thời gian của thuộc tính đó.\n",
        "\n",
        "Nhóm tg xây dựng 242 mô hình- mỗi mô hình tương ứng với 1 thuộc tính.\n",
        "Mỗi mô hình sẽ được đào tạo vào tháng đầu tiên của dữ liệu đào tạo và sẽ chỉ sử dụng một feature duy nhất. Sau đó, dự đoán kết quả trên tháng cuối cùng của dữ liệu đào tạo. \n",
        "\n",
        "Với các feature cho giá trị AUC trên tập train hoặc validation < 0.5 (tức là có một số đặc điểm của feature đó có ở tập train nhưng không có ở tập test) tác giả cho rằng đó là các thuộc tính yếu, loại bỏ và xem giá trị AUC có tăng hay không.\n",
        "Bằng cách này, ta loại bỏ được 19 cột thuộc tính. Ngoài ra, ta cũng loại bỏ 7 cột D chủ yếu là giá trị NAN."
      ],
      "metadata": {
        "id": "-sFbvU6WNy_a"
      },
      "id": "-sFbvU6WNy_a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5c1d22",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.867907Z",
          "iopub.status.idle": "2021-12-01T14:39:21.868242Z"
        },
        "id": "9f5c1d22"
      },
      "outputs": [],
      "source": [
        "#Bỏ các feature  không nhất quán về thời gian và 7 cột D_nan\n",
        "\n",
        "cols = list( X_train.columns )\n",
        "cols.remove('TransactionDT') \n",
        "for c in ['D6','D7','D8','D9','D12','D13','D14']:\n",
        "    cols.remove(c) # a lot nan\n",
        "    \n",
        "# FAILED TIME CONSISTENCY TEST\n",
        "for c in ['C3','M5','id_08','id_33']:\n",
        "    cols.remove(c)\n",
        "for c in ['card4','id_07','id_14','id_21','id_30','id_32','id_34']:\n",
        "    cols.remove(c)\n",
        "for c in ['id_'+str(x) for x in range(22,28)]:\n",
        "    cols.remove(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266efadb",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.869266Z",
          "iopub.status.idle": "2021-12-01T14:39:21.869602Z"
        },
        "id": "266efadb"
      },
      "outputs": [],
      "source": [
        "print('NOW USING THE FOLLOWING',len(cols),'FEATURES.')\n",
        "np.array(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889b9423",
      "metadata": {
        "id": "889b9423"
      },
      "source": [
        "##### Xác thực chéo - Local Validation\n",
        "Xác thực dựa trên thời gian - tháng.\n",
        "\n",
        "Đánh giá các thuộc tính bằng cách huấn luyện mô hình trên 75% dữ liệu đầu tiên và dự đoán trên 25% dữ liệu cuối cùng. (tương đương 4.5 tháng đầu tiên và 1.5 tháng cuối cùng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb0a3020",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.870573Z",
          "iopub.status.idle": "2021-12-01T14:39:21.871018Z"
        },
        "id": "cb0a3020"
      },
      "outputs": [],
      "source": [
        "#TRAIN 75% PREDICT 25%\n",
        "idxT = X_train.index[:3*len(X_train)//4]\n",
        "idxV = X_train.index[3*len(X_train)//4:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mô hình XGBoots\n",
        "Nhóm tác giả xây dựng hai mô hình XGB. \n",
        "1. Mô hình đầu tiên không sử dụng \"magic feature\" tức là \"UID\" và đạt được điểm LB = 0,95. \n",
        "2. Mô hình thứ hai sử dụng các \"magic feature\" UIS và đạt được LB = 0,96."
      ],
      "metadata": {
        "id": "QKAVXdwwP8H_"
      },
      "id": "QKAVXdwwP8H_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tổng quan về mô hình"
      ],
      "metadata": {
        "id": "je6y6v2gQQP_"
      },
      "id": "je6y6v2gQQP_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Học kết hợp :\n",
        ">Mô hình học máy trong đó nhiều mô hình \"yếu“ (weak learner) được đào tạo để giải quyết cùng 1 bài toán và kết hợp thành 1 mô hình mạnh hơn để đạt được kết quả tốt hơn.\n",
        "- Boosting (thuộc Ensemble Methods):\n",
        ">Phương pháp xây dựng một loạt các mô hình giống nhau, trong đó các mô hình sau sẽ cố gắng học để hạn chế lỗi của mô hình trước. Mỗi mô hình có thể xem là một base model hay weak learner.\n",
        "- Gradient boosting (thuộc Boosting):\n",
        ">Phương pháp xây dựng một loạt các mô hình giống nhau, trong đó các mô hình sau sẽ cố gắng học để hạn chế lỗi của mô hình trước. Thuật toán dựa vào Gradient Descent và ở đây mỗi base model là thường một cây quyết định.\n",
        ">\n",
        ">Với GB, 2 framework phổ biến nhất là XGBoost và LightGBM\n",
        "- XGBoots: \n",
        ">\n",
        "- XGB Hyperparameters chính\n",
        "- Tuning Hyperparameters trong mô hình của tác giả?"
      ],
      "metadata": {
        "id": "1h-ddwuASF4H"
      },
      "id": "1h-ddwuASF4H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xây dựng mô hình XGB - \"non\" UID"
      ],
      "metadata": {
        "id": "-M6Ykrn-VYgV"
      },
      "id": "-M6Ykrn-VYgV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78fdb1f8",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.872226Z",
          "iopub.status.idle": "2021-12-01T14:39:21.872671Z"
        },
        "id": "78fdb1f8"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "print(\"XGBoost version:\", xgb.__version__)\n",
        "\n",
        "if BUILD95:\n",
        "    clf = xgb.XGBClassifier( \n",
        "        n_estimators=2000,\n",
        "        max_depth=12, \n",
        "        learning_rate=0.02, \n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.4, \n",
        "        missing=-1, \n",
        "        eval_metric='auc',\n",
        "        # USE CPU\n",
        "        #nthread=4,\n",
        "        #tree_method='hist' \n",
        "        # USE GPU\n",
        "        tree_method='gpu_hist' \n",
        "    )\n",
        "    h = clf.fit(X_train.loc[idxT,cols], y_train[idxT], \n",
        "        eval_set=[(X_train.loc[idxV,cols],y_train[idxV])],\n",
        "        verbose=50, early_stopping_rounds=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f72fef",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.873708Z",
          "iopub.status.idle": "2021-12-01T14:39:21.874102Z"
        },
        "id": "63f72fef"
      },
      "outputs": [],
      "source": [
        "if BUILD95:\n",
        "\n",
        "    feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,cols)), columns=['Value','Feature'])\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).iloc[:50])\n",
        "    plt.title('XGB95 Most Important Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    del clf, h; x=gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce203c7a",
      "metadata": {
        "id": "ce203c7a"
      },
      "source": [
        "##### Predict test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3cf520f",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.875042Z",
          "iopub.status.idle": "2021-12-01T14:39:21.875496Z"
        },
        "id": "e3cf520f"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
        "X_train['DT_M'] = X_train['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
        "X_train['DT_M'] = (X_train['DT_M'].dt.year-2017)*12 + X_train['DT_M'].dt.month \n",
        "\n",
        "X_test['DT_M'] = X_test['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
        "X_test['DT_M'] = (X_test['DT_M'].dt.year-2017)*12 + X_test['DT_M'].dt.month "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KFOLD**\n",
        "\n",
        "-kfold?\n",
        "\n",
        "-Dùng kfold trong solution thế nào\n"
      ],
      "metadata": {
        "id": "fjfPZwaBUbXk"
      },
      "id": "fjfPZwaBUbXk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d4eae7",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.876400Z",
          "iopub.status.idle": "2021-12-01T14:39:21.876902Z"
        },
        "id": "94d4eae7"
      },
      "outputs": [],
      "source": [
        "if BUILD95:\n",
        "    oof = np.zeros(len(X_train))\n",
        "    preds = np.zeros(len(X_test))\n",
        "\n",
        "    skf = GroupKFold(n_splits=6)\n",
        "    for i, (idxT, idxV) in enumerate( skf.split(X_train, y_train, groups=X_train['DT_M']) ):\n",
        "        month = X_train.iloc[idxV]['DT_M'].iloc[0]\n",
        "        print('Fold',i,'withholding month',month)\n",
        "        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n",
        "        clf = xgb.XGBClassifier(\n",
        "            n_estimators=5000,\n",
        "            max_depth=12,\n",
        "            learning_rate=0.02,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.4,\n",
        "            missing=-1,\n",
        "            eval_metric='auc',\n",
        "            # USE CPU\n",
        "            #nthread=4,\n",
        "            #tree_method='hist'\n",
        "            # USE GPU\n",
        "            tree_method='gpu_hist' \n",
        "        )        \n",
        "        h = clf.fit(X_train[cols].iloc[idxT], y_train.iloc[idxT], \n",
        "                eval_set=[(X_train[cols].iloc[idxV],y_train.iloc[idxV])],\n",
        "                verbose=100, early_stopping_rounds=200)\n",
        "    \n",
        "        oof[idxV] += clf.predict_proba(X_train[cols].iloc[idxV])[:,1]\n",
        "        preds += clf.predict_proba(X_test[cols])[:,1]/skf.n_splits\n",
        "        del h, clf\n",
        "        x=gc.collect()\n",
        "    print('#'*20)\n",
        "    print ('XGB95 OOF CV=',roc_auc_score(y_train,oof))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0242b47",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.877851Z",
          "iopub.status.idle": "2021-12-01T14:39:21.878278Z"
        },
        "id": "b0242b47"
      },
      "outputs": [],
      "source": [
        "if BUILD95:\n",
        "    plt.hist(oof,bins=100)\n",
        "    plt.ylim((0,5000))\n",
        "    plt.title('XGB OOF')\n",
        "    plt.show()\n",
        "\n",
        "    X_train['oof'] = oof\n",
        "    X_train.reset_index(inplace=True)\n",
        "    X_train[['TransactionID','oof']].to_csv('oof_xgb_95.csv')\n",
        "    X_train.set_index('TransactionID',drop=True,inplace=True)\n",
        "    \n",
        "else: X_train['oof'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92bffa9",
      "metadata": {
        "id": "a92bffa9"
      },
      "source": [
        "##### Kaggle Submission File XGB_95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6929f3",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.879121Z",
          "iopub.status.idle": "2021-12-01T14:39:21.879544Z"
        },
        "id": "8e6929f3"
      },
      "outputs": [],
      "source": [
        "if BUILD95:\n",
        "    sample_submission = pd.read_csv('sample_submission.csv')\n",
        "    sample_submission.isFraud = preds\n",
        "    sample_submission.to_csv('sub_xgb_95.csv',index=False)\n",
        "\n",
        "    plt.hist(sample_submission.isFraud,bins=100)\n",
        "    plt.ylim((0,5000))\n",
        "    plt.title('XGB95 Submission')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65900270",
      "metadata": {
        "id": "65900270"
      },
      "source": [
        "![image](http://www.playagricola.com/Kaggle/9510.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xây dựng mô hình XGB - used UID"
      ],
      "metadata": {
        "id": "OSKlJWuZXSOK"
      },
      "id": "OSKlJWuZXSOK"
    },
    {
      "cell_type": "markdown",
      "id": "3f6e2bae",
      "metadata": {
        "id": "3f6e2bae"
      },
      "source": [
        "#### The Magic Feature - UID\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f7b3600",
      "metadata": {
        "id": "2f7b3600"
      },
      "source": [
        "##### Cách hoạt động\n",
        "* Bước 1: Chúng ta cần tạo ra cột UID để định danh khách hàng\n",
        "* Bước 2: Tạo ra các tính năng nhóm tổng hợp (Nhóm theo UID)\n",
        "* Bước 3: Xóa đi cột UID\n",
        "\n",
        "Giả sử chúng ta có 10 giao dịch `A, B, C, D, E, F, G, H, I, J` như hình bên dưới.  \n",
        "  \n",
        "<img src=\"https://github.com/trandaitai327/IEEE-CIS-Fraud-Detection/blob/main/table.jpg?raw=1\" alt=\"table\" width=\"700\">\n",
        "\n",
        "\n",
        "Nếu chỉ sử dung FeatureX. \n",
        "Chúng ta dự đoán đúng được 7 trên 10 giao dịch như hình bên dưới\n",
        " \n",
        " \n",
        "<img src=\"https://github.com/trandaitai327/IEEE-CIS-Fraud-Detection/blob/main/tran.jpg?raw=1\" alt=\"tran\" height =\"500\" width=\"700\">\n",
        "  \n",
        "  \n",
        "Nếu có thêm cột UID, chúng ta có thể tạo ra cột GroupX bằng cách lấy trung bình FeatureX theo UID. \n",
        "\n",
        "Chúng ta có thể dự đoán đúng 100% các giao dịch như hình bên dưới\n",
        "  \n",
        "  \n",
        "<img src=\"https://github.com/trandaitai327/IEEE-CIS-Fraud-Detection/blob/main/cred.jpg?raw=1\" alt=\"cred\" height = \"450\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b402c3",
      "metadata": {
        "id": "a9b402c3"
      },
      "source": [
        "##### Tạo UID \n",
        "Đầu tiên,một UID sẽ giúp mô hình tìm thấy khách hàng (credit card).\n",
        "\n",
        "Thực hiện tạo một thuộc tính UID mới để giúp mô hình nhận biết được các khách hành."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47cfc0d9",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.880599Z",
          "iopub.status.idle": "2021-12-01T14:39:21.881043Z"
        },
        "id": "47cfc0d9"
      },
      "outputs": [],
      "source": [
        "X_train['day'] = X_train.TransactionDT / (24*60*60)\n",
        "X_train['uid'] = X_train.card1_addr1.astype(str)+'_'+np.floor(X_train.day-X_train.D1).astype(str)\n",
        "\n",
        "X_test['day'] = X_test.TransactionDT / (24*60*60)\n",
        "X_test['uid'] = X_test.card1_addr1.astype(str)+'_'+np.floor(X_test.day-X_test.D1).astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UID này không hoàn hảo. Nhiều giá trị UID chứa 2 hoặc nhiều khách hàng bên trong. Tuy nhiên, mô hình của này sẽ phát hiện điều này và bằng cách thêm các splits trên cây, điều này giúp tách các UID và tìm ra khách hàng riêng lẻ duy nhất bên trong UID đó. Và để làm được điều đó ta cần các thuộc tính tổng hợp để phân loại khách hàng."
      ],
      "metadata": {
        "id": "HMU5ckcHY5LC"
      },
      "id": "HMU5ckcHY5LC"
    },
    {
      "cell_type": "markdown",
      "id": "d89d427e",
      "metadata": {
        "id": "d89d427e"
      },
      "source": [
        "##### Tổng hợp thuộc tính - Group Aggregation Features\n",
        "Cần tạo nhiều thuộc tính tổng hợp mới theo giá trị trung bình/ độ lệch chuẩn/nunique thông qua \"UID\". Điều này giúp phân loại khách hàng.\n",
        "\n",
        "Cụ thể ta thêm 47 thuộc tính tổng hợp mới.\n",
        ">Lưu ý rằng sau khi tổng hợp, xóa UID khỏi mô hình, không sử dụng trực tiếp UID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59c7dac",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.881939Z",
          "iopub.status.idle": "2021-12-01T14:39:21.882342Z"
        },
        "id": "b59c7dac"
      },
      "outputs": [],
      "source": [
        "#Tổng hợp thuộc tính\n",
        "\n",
        "%%time\n",
        "# FREQUENCY ENCODE UID\n",
        "encode_FE(X_train,X_test,['uid'])\n",
        "# AGGREGATE \n",
        "encode_AG(['TransactionAmt','D4','D9','D10','D15'],['uid'],['mean','std'],fillna=True,usena=True)\n",
        "# AGGREGATE\n",
        "encode_AG(['C'+str(x) for x in range(1,15) if x!=3],['uid'],['mean'],X_train,X_test,fillna=True,usena=True)\n",
        "# AGGREGATE\n",
        "encode_AG(['M'+str(x) for x in range(1,10)],['uid'],['mean'],fillna=True,usena=True)\n",
        "# AGGREGATE\n",
        "encode_AG2(['P_emaildomain','dist1','DT_M','id_02','cents'], ['uid'], train_df=X_train, test_df=X_test)\n",
        "# AGGREGATE\n",
        "encode_AG(['C14'],['uid'],['std'],X_train,X_test,fillna=True,usena=True)\n",
        "# AGGREGATE \n",
        "encode_AG2(['C13','V314'], ['uid'], train_df=X_train, test_df=X_test)\n",
        "# AGGREATE \n",
        "encode_AG2(['V127','V136','V309','V307','V320'], ['uid'], train_df=X_train, test_df=X_test)\n",
        "# NEW FEATURE\n",
        "X_train['outsider15'] = (np.abs(X_train.D1-X_train.D15)>3).astype('int8')\n",
        "X_test['outsider15'] = (np.abs(X_test.D1-X_test.D15)>3).astype('int8')\n",
        "print('outsider15')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loại bỏ UID và các thuộc tính được sử dụng để xác định UID.\n",
        "\n",
        "Bỏ các thuộc tính không đảm bảo tính nhất quán về thời gian."
      ],
      "metadata": {
        "id": "pPvJohakanaq"
      },
      "id": "pPvJohakanaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4f3660",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.883176Z",
          "iopub.status.idle": "2021-12-01T14:39:21.883572Z"
        },
        "id": "6b4f3660"
      },
      "outputs": [],
      "source": [
        "cols = list( X_train.columns )\n",
        "cols.remove('TransactionDT')\n",
        "for c in ['D6','D7','D8','D9','D12','D13','D14']:\n",
        "    cols.remove(c)\n",
        "for c in ['oof','DT_M','day','uid']:\n",
        "    cols.remove(c)\n",
        "    \n",
        "# FAILED TIME CONSISTENCY TEST\n",
        "for c in ['C3','M5','id_08','id_33']:\n",
        "    cols.remove(c)\n",
        "for c in ['card4','id_07','id_14','id_21','id_30','id_32','id_34']:\n",
        "    cols.remove(c)\n",
        "for c in ['id_'+str(x) for x in range(22,28)]:\n",
        "    cols.remove(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27b470e",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.884425Z",
          "iopub.status.idle": "2021-12-01T14:39:21.884798Z"
        },
        "id": "e27b470e"
      },
      "outputs": [],
      "source": [
        "print('NOW USING THE FOLLOWING',len(cols),'FEATURES.')\n",
        "np.array(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228df176",
      "metadata": {
        "id": "228df176"
      },
      "source": [
        "##### Local Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea650d0",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.885847Z",
          "iopub.status.idle": "2021-12-01T14:39:21.886325Z"
        },
        "id": "9ea650d0"
      },
      "outputs": [],
      "source": [
        "#TRAIN 75% PREDICT 25%\n",
        "idxT = X_train.index[:3*len(X_train)//4]\n",
        "idxV = X_train.index[3*len(X_train)//4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "872b1b09",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.887132Z",
          "iopub.status.idle": "2021-12-01T14:39:21.887631Z"
        },
        "id": "872b1b09"
      },
      "outputs": [],
      "source": [
        "if BUILD96:\n",
        "    clf = xgb.XGBClassifier( \n",
        "        n_estimators=2000,\n",
        "        max_depth=12, \n",
        "        learning_rate=0.02, \n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.4, \n",
        "        missing=-1, \n",
        "        eval_metric='auc',\n",
        "        #nthread=4,\n",
        "        #tree_method='hist' \n",
        "        tree_method='gpu_hist' \n",
        "    )\n",
        "    h = clf.fit(X_train.loc[idxT,cols], y_train[idxT], \n",
        "        eval_set=[(X_train.loc[idxV,cols],y_train[idxV])],\n",
        "        verbose=50, early_stopping_rounds=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb06a43",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.888630Z",
          "iopub.status.idle": "2021-12-01T14:39:21.889009Z"
        },
        "id": "2eb06a43"
      },
      "outputs": [],
      "source": [
        "if BUILD96:\n",
        "\n",
        "    feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,cols)), columns=['Value','Feature'])\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).iloc[:50])\n",
        "    plt.title('XGB96 Most Important')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "        \n",
        "    del clf, h; x=gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51d4d83",
      "metadata": {
        "id": "a51d4d83"
      },
      "source": [
        "##### Predict test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53239b15",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.889873Z",
          "iopub.status.idle": "2021-12-01T14:39:21.890360Z"
        },
        "id": "53239b15"
      },
      "outputs": [],
      "source": [
        "if BUILD96:\n",
        "    oof = np.zeros(len(X_train))\n",
        "    preds = np.zeros(len(X_test))\n",
        "\n",
        "    skf = GroupKFold(n_splits=6)\n",
        "    for i, (idxT, idxV) in enumerate( skf.split(X_train, y_train, groups=X_train['DT_M']) ):\n",
        "        month = X_train.iloc[idxV]['DT_M'].iloc[0]\n",
        "        print('Fold',i,'withholding month',month)\n",
        "        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n",
        "        clf = xgb.XGBClassifier(\n",
        "            n_estimators=5000,\n",
        "            max_depth=12,\n",
        "            learning_rate=0.02,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.4,\n",
        "            missing=-1,\n",
        "            eval_metric='auc',\n",
        "            # USE CPU\n",
        "            #nthread=4,\n",
        "            #tree_method='hist'\n",
        "            # USE GPU\n",
        "            tree_method='gpu_hist' \n",
        "        )        \n",
        "        h = clf.fit(X_train[cols].iloc[idxT], y_train.iloc[idxT], \n",
        "                eval_set=[(X_train[cols].iloc[idxV],y_train.iloc[idxV])],\n",
        "                verbose=100, early_stopping_rounds=200)\n",
        "    \n",
        "        oof[idxV] += clf.predict_proba(X_train[cols].iloc[idxV])[:,1]\n",
        "        preds += clf.predict_proba(X_test[cols])[:,1]/skf.n_splits\n",
        "        del h, clf\n",
        "        x=gc.collect()\n",
        "    print('#'*20)\n",
        "    print ('XGB96 OOF CV=',roc_auc_score(y_train,oof))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e1b0e1",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-01T14:39:21.891537Z",
          "iopub.status.idle": "2021-12-01T14:39:21.892154Z"
        },
        "id": "e5e1b0e1"
      },
      "outputs": [],
      "source": [
        "if BUILD96:\n",
        "    plt.hist(oof,bins=100)\n",
        "    plt.ylim((0,5000))\n",
        "    plt.title('XGB OOF')\n",
        "    plt.show()\n",
        "\n",
        "    X_train['oof'] = oof\n",
        "    X_train.reset_index(inplace=True)\n",
        "    X_train[['TransactionID','oof']].to_csv('oof_xgb_96.csv')\n",
        "    X_train.set_index('TransactionID',drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kaggle Submission File XGB_96"
      ],
      "metadata": {
        "id": "qZNwyQSCbidS"
      },
      "id": "qZNwyQSCbidS"
    },
    {
      "cell_type": "code",
      "source": [
        "if BUILD96:\n",
        "    sample_submission = pd.read_csv('sample_submission.csv')\n",
        "    sample_submission.isFraud = preds\n",
        "    sample_submission.to_csv('sub_xgb_96.csv',index=False)\n",
        "\n",
        "    plt.hist(sample_submission.isFraud,bins=100)\n",
        "    plt.ylim((0,5000))\n",
        "    plt.title('XGB96 Submission')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "m4CSNfIzbyHJ"
      },
      "id": "m4CSNfIzbyHJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình XGB sử dụng \"magic work\" có giá trị AUC = 0.9472 trên tập validation và AUC = 0.96 trên LB,  **tăng 0.01** đồng thời trên tập validation và LB so với mô hình XGB không sử dụng \"magic work - UID\"."
      ],
      "metadata": {
        "id": "tBvb4Bq1dNMq"
      },
      "id": "tBvb4Bq1dNMq"
    },
    {
      "cell_type": "markdown",
      "id": "7ef2969f",
      "metadata": {
        "id": "7ef2969f"
      },
      "source": [
        "## Nhìn lại quá trình làm đồ án"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e176d47",
      "metadata": {
        "id": "1e176d47"
      },
      "source": [
        "Sau bao ngày vất vả làm đồ án thì bây giờ đã kết thúc. Bây giờ là lúc để ngồi uống coffee và tĩnh tâm nhìn lại quá trình làm.\n",
        "\n",
        "- Mỗi thành viên: Đã gặp những khó khăn gì? (Hay mọi chuyện đều thuận lợi)\n",
        "- Mỗi thành viên: Có học được gì hữu ích? (Hay không học được gì)\n",
        "- Nhóm: Nếu có thêm thời gian thì sẽ làm gì?\n",
        "\n",
        "Phần này có sao thì bạn nói vậy thôi, chứ không phải là viết\n",
        "cho có, hoặc tự chế ra để nghe cho hay."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86c831b",
      "metadata": {
        "id": "e86c831b"
      },
      "source": [
        "## Tài liệu tham khảo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0230b4c",
      "metadata": {
        "id": "e0230b4c"
      },
      "source": [
        "Để hoàn thành đồ án này, nhóm bạn đã tham khảo những tài liệu nào?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Report.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8717feef",
        "59291c79",
        "6cdd2151",
        "a9079d59",
        "7b689dcd",
        "ded028c9",
        "8fe35936",
        "d31f12b7",
        "1edef9ff",
        "e1eefd35",
        "b5fb6fd2",
        "d7e0f3fb",
        "-sFbvU6WNy_a"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
